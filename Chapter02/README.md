# Chapter 2

## Notebooks

• [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/your-repo/designing-llm-apps/blob/main/Chapter02/2.3_realnewslike.ipynb) `2.3_realnewslike.ipynb`

• [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/your-repo/designing-llm-apps/blob/main/Chapter02/2.5.1_justtext.ipynb) `2.5.1_justtext.ipynb`

• [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/your-repo/designing-llm-apps/blob/main/Chapter02/2.5.1_langdetect.ipynb) `2.5.1_langdetect.ipynb`

• [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/your-repo/designing-llm-apps/blob/main/Chapter02/2.5.2_wikipedia_KenlmModel.ipynb) `2.5.2_wikipedia_KenlmModel.ipynb`

• [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/your-repo/designing-llm-apps/blob/main/Chapter02/C4_Dataset_Analysis.ipynb) `C4_Dataset_Analysis.ipynb`

• [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/your-repo/designing-llm-apps/blob/main/Chapter02/Ch2_Cosmopedia.ipynb) `Ch2_Cosmopedia.ipynb`

• [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/your-repo/designing-llm-apps/blob/main/Chapter02/CH2_FasttextClassifieripynb.ipynb) `CH2_FasttextClassifieripynb.ipynb`

## References

* OpenAI, "GPT-4 Technical Report", 15 Mar 2023, https://arxiv.org/abs/2303.08774
* https://huggingface.co/blog/rlhf
* https://time.com/6247678/openai-chatgpt-kenya-workers/
* https://huggingface.co/blog/bloom-megatron-deepspeed
* https://oreil.ly/j6UT8
* https://oreil.ly/3W3TH
* Zhang, "Open Pretrained Transformers - Susan Zhang | Stanford MLSys #77", 23 Feb 2023, https://oreil.ly/lGwPa
* Bender & Koller, "Climbing towards NLU: On Meaning, Form, and Understanding in the Age of Data", 5 Jul 2020, https://oreil.ly/3iYA2
* Chandu et al., "Grounding 'Grounding' in NLP", 4 Jun 2021, https://arxiv.org/abs/2106.02192
* Graesser, "Prose Comprehension Beyond the Word", 1981, https://oreil.ly/jg4tW 
* "Principle of least effort", https://oreil.ly/UX7Nd 
* Chandu et al., "Grounding 'Grounding' in NLP", https://oreil.ly/PbIhT 
* Xu et al., "Multimodal Learning with Transformers: A Survey", 13 Jun 2022, https://arxiv.org/abs/2206.06488 
* "Debate: Do Language Models Need Sensory Grounding for Meaning and Understanding?", https://oreil.ly/oacht
* OpenAI, "Let's Verify Step by Step", https://oreil.ly/Qlntp
* Liu et al., "We're Afraid Language Models Aren't Modeling Ambiguity", 27 Apr 2023, https://arxiv.org/abs/2304.14399 
* "How much LLM training data is there, in the limit?", 9 May 2025, https://oreil.ly/XnmHL
* Muennighoff et al., "Scaling Data-Constrained Language Models", 25 May 2023, https://arxiv.org/abs/2305.16264 
* Xue et al., "To Repeat or Not To Repeat: Insights from Scaling LLM under Token-Crisis", 5 Oct 2023, https://arxiv.org/pdf/2305.13230 
* Goyal et al., "Scaling Laws for Data Filtering—Data Curation cannot be Compute Agnostic", https://arxiv.org/pdf/2404.07177 
* "OpenAI and Wall Street Journal owner News Corp sign content deal", https://oreil.ly/ygIO2
* https://commoncrawl.org/overview
* Touvron et al., "LLaMA: Open and Efficient Foundation Language Models", 27 Reb 2023, https://arxiv.org/abs/2302.13971
* https://huggingface.co/datasets/HuggingFaceFW/fineweb
* https://huggingface.co/datasets/HuggingFaceFW/fineweb-edu
* Bandy et al., "Addressing "Documentation Debt" in Machine Learning Research: A Retrospective Datasheet for BookCorpus", 11 May 2021, https://arxiv.org/abs/2105.05241
* https://huggingface.co/datasets/monology/pile-uncopyrighted
* https://www.dataprovenance.org/Consent_in_Crisis.pdf
* Vincent, "The lawsuit that could rewrite the rules of AI copyright", 8 Nov 2022, https://oreil.ly/QcIKy
* Li et al., "Textbooks Are All You Need II: phi-1.5 technical report", 11 Sep 2023, https://arxiv.org/pdf/2309.05463
* https://huggingface.co/datasets/HuggingFaceTB/smollm-corpus
* https://atlas.nomic.ai/map/cosmopedia
* https://huggingface.co/datasets/HuggingFaceTB/cosmopedia-100k
* Aghajanyan et al., "HTLM: Hyper-Text Pre-Training and Prompting of Language Models", 14 Jul 2021, https://arxiv.org/abs/2107.06955
* "List-of-Dirty-Naughty-Obscene-and-Otherwise-Bad-Words", http://oreil.ly/w3u_r 
* "Kullback-Leibler Divergence Explained", https://oreil.ly/gd5GH
* Grattafiori et al., "The Llama 3 Herd of Models", 23 Jul 2024, https://arxiv.org/pdf/2407.21783
* https://fasttext.cc/docs/en/supervised-tutorial.html
* https://rua.ua.es/dspace/bitstream/10045/122846/1/PLN_68_01.pdf
* https://oreil.ly/xwYjY
* https://github.com/kpu/kenlm
* Dodge et al., "Documenting Large Webtext Corpora: A Case Study on the Colossal Clean Crawled Corpus", 18 Apr 2021, https://arxiv.org/abs/2104.08758
* https://oreil.ly/2RO9f
* Lee et al., "Deduplicating Training Data Makes Language Models Better", 14 Jul 2021, https://arxiv.org/abs/2107.06499
* Carlini et al., "Extracting Training Data from Large Language Models", 14 Dec 2020, https://arxiv.org/abs/2012.07805
* https://www.law.cornell.edu/cfr/text/34/300.32
* https://github.com/jeffhj/LM_PersonalInfoLeak
* https://github.com/google-research/lm-extraction-benchmark
* Tramer et al., "Truth Serum: Poisoning Machine Learning Models to Reveal Their Secrets", 6 Oct 2022, https://arxiv.org/pdf/2204.00032
* https://oreil.ly/8YwG9
* https://en.wikipedia.org/wiki/Luhn_algorithm
* "huggingface  tiiuae/falcon-refinedweb", https://oreil.ly/jto4m
* Jorgensen & Yu, "Hands-On Differential Privacy", 2022, https://oreil.ly/TRbsf
* Abadi et al., "Deep Learning with Differential Privacy", 1 Jul 2016, https://arxiv.org/abs/1607.00133
* Bourtoule et al., "Machine Unlearning", 15 Dec 2020, https://arxiv.org/pdf/1912.03817
* Ippolito et al., "Preventing Verbatim Memorization in Language Models Gives a False Sense of Privacy", 31 Oct 2022, https://arxiv.org/abs/2210.17546
* Ippolito et al., "Preventing Verbatim Memorization in Language Models Gives a False Sense of Privacy", 31 Oct 2022, https://arxiv.org/abs/2210.17546
* Dodge et al., "Documenting Large Webtext Corpora: A Case Study on the Colossal Clean Crawled Corpus", 18 Apr 2021, https://arxiv.org/abs/2104.08758
* Brown et al., "Language Models are Few-Shot Learners", 28 May 2020, https://arxiv.org/abs/2005.14165
* Yang et al., "Rethinking Benchmark and Contamination for Language Models with Rephrased Samples", 11 Nov 2023, https://arxiv.org/pdf/2311.04850
* Gao et al., "The Pile: An 800GB Dataset of Diverse Text for Language Modeling", 31 Dec 2020, https://arxiv.org/pdf/2101.00027
* Xie et al., "DoReMi: Optimizing Data Mixtures Speeds Up Language Model Pretraining", 21 Nov 2023, https://arxiv.org/pdf/2305.10429
* Liu et al., "RegMix: Data Mixture as Regression for Language Model Pre-training", 1 Jul 2024, https://arxiv.org/abs/2407.01492
* Grattafiori et al., "The Llama 3 Herd of Models", 23 Jul 2024, https://arxiv.org/pdf/2407.21783
* https://arxiv.org/pdf/2408.10914
* https://github.com/huggingface/datatrove
* Razeghi et al., "Impact of Pretraining Term Frequencies on Few-Shot Reasoning", 15 Feb 2022, https://arxiv.org/abs/2202.07206
* McCoy et al., "Embers of Autoregression: Understanding Large Language Models Through the Problem They are Trained to Solve", 24 Sep 2023, https://arxiv.org/pdf/2309.13638
* Gao et al., "The Pile: An 800GB Dataset of Diverse Text for Language Modeling", 31 Dec 2020, https://arxiv.org/abs/2101.00027
* Hall et al., "A Systematic Study of Bias Amplification", 27 Jan 2022, https://arxiv.org/abs/2201.11706
* https://aclanthology.org/2021.acl-long.170.pdf
* https://gitnux.org/reddit-user-statistics/
* Dodge et al., "Documenting Large Webtext Corpora: A Case Study on the Colossal Clean Crawled Corpus", 18 Apr 2021, https://arxiv.org/abs/2104.08758
* Biderman et al., "Pythia: A Suite for Analyzing Large Language Models Across Training and Scaling", 31 May 2023, https://arxiv.org/pdf/2304.01373