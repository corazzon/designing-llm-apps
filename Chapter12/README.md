# Chapter 12

## References 
* Kandpal et al., "Large Language Models Struggle to Learn Long-Tail Knowledge", 27 Jul 2023, https://arxiv.org/pdf/2211.08411
* Jagielski et al., "Measuring Forgetting of Memorized Training Examples", 9 May 2023, https://arxiv.org/pdf/2207.00099
* Mallen et al., "When Not to Trust Language Models: Investigating Effectiveness of Parametric and Non-Parametric Memories", 2 Jul 2023, https://aclanthology.org/2023.acl-long.546.pdf
* "Understanding TF-IDF (Term Frequency-Inverse Document Frequency)", https://oreil.ly/5be9z
* Wang et al., "Query2doc: Query Expansion with Large Language Models", 11 Oct 2023, https://arxiv.org/pdf/2303.07678
* Gao et al., "Precise Zero-Shot Dense Retrieval without Relevance Labels", 20 Dec 2022, https://arxiv.org/pdf/2212.10496
* Li et al., "Can Query Expansion Improve Generalization of Strong Cross-Encoder Rankers?", 30 Apr 2024, https://arxiv.org/pdf/2311.09175
* "LLM Playbooks", https://oreil.ly/llm-playbooks
* "Tweaking the Base Score: LuceneSolr Similarities Explained & Automatically Scaling Solr - Sematext", https://oreil.ly/zyke4
* Pradeep et al., "How Does Generative Retrieval Scale to Millions of Passages?", 19 May 2023, https://arxiv.org/pdf/2305.11841
* "Transformer Memory as a Differentiable Search Index", 21 Oct 2022, https://arxiv.org/pdf/2202.06991
* Askari et al., "Generative Retrieval with Few-shot Indexing", 4 Aug 2024, https://arxiv.org/pdf/2408.02152
* Zhang et al., "Retrieve Anything To Augment Large Language Models", 25 Oct 2023, https://arxiv.org/pdf/2310.07554
* "LLM Playbooks", https://oreil.ly/llm-playbooks
* Khattab et al., "ColBERT: Efficient and Effective Passage Search via Contextualized Late Interaction over BERT", 4 Jun 2020, https://arxiv.org/abs/2004.12832
* "Strategies for Effective and Efficient Text Ranking Using Large Language Models", https://oreil.ly/DvmtC
* Sun et al., "Is ChatGPT Good at Search? Investigating Large Language Models as Re-Ranking Agents", 28 Dec 2024, https://arxiv.org/abs/2304.09542
* Pradeep et al., "RankVicuna: Zero-Shot Listwise Document Reranking with Open-Source Large Language Models", 26 Sep 2023, https://arxiv.org/abs/2309.15088
* Pradeep et al., "RankZephyr: Effective and Robust Zero-Shot Listwise Reranking is a Breeze!", 5 Dec 2023, https://arxiv.org/abs/2312.02724
* Xu et al., "RECOMP: IMPROVING RETRIEVAL-AUGMENTED LMS WITH COMPRESSION AND SELECTIVE AUGMENTATION", 6 Oct 2023, https://arxiv.org/pdf/2310.04408
* Yu et al., "Chain-of-Note: Enhancing Robustness in Retrieval-Augmented Language Models", 3 Oct 2024, https://arxiv.org/pdf/2311.09210
* Liu et al., "Lost in the Middle: How Language Models Use Long Contexts", 20 Nov 2023, https://arxiv.org/abs/2307.03172
* Jiang et al., "Active Retrieval Augmented Generation", 22 Oct 2023, https://arxiv.org/pdf/2305.06983
* "Operating System â€” Hierarchy of Memory", https://oreil.ly/vcciM
* "Letta AI - Conversational Memory Platform", https://github.com/letta-ai/letta
* "Mem0 - AI Memory Management", https://github.com/mem0ai/mem0
* "Introducing 100K Context Windows", http://oreil.ly/ucbD-
* "LLMTest_NeedleInAHaystack", http://oreil.ly/M8Jc9


    