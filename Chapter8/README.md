# Chapter 8

## References 

* Askell et al., "A General Language Assistant as a Laboratory for Alignment", 9 Dec 2021, https://arxiv.org/abs/2112.00861
* "huggingface Anthropic/hh-rlhf", https://oreil.ly/kzSQf
* https://oreil.ly/llm-playbooks
* Lee et al., "Factuality Enhanced Language Models for Open-Ended Text Generation", 9 Jun 2022, https://arxiv.org/abs/2206.04624
* Lee et al., "Factuality Enhanced Language Models for Open-Ended Text Generation", 9 Jun 2022, https://arxiv.org/abs/2206.04624
* Chuang et al., "DOLA: DECODING BY CONTRASTING LAYERS IMPROVES FACTUALITY IN LARGE LANGUAGE MODELS", 11 Mar 2024, https://arxiv.org/pdf/2309.03883
* Lee et al., "Factuality Enhanced Language Models for Open-Ended Text Generation", 2 Mar 2025, https://arxiv.org/pdf/2206.04624
* Chuang et al., "Lookback Lens: Detecting and Mitigating Contextual Hallucinations in Large Language Models Using Only Attention Maps", 3 Oct 2024, https://arxiv.org/pdf/2407.07071
* Zhang et al., "Knowledge Overshadowing Causes Amalgamated Hallucination in Large Language Models", 10 Jul 2024, https://arxiv.org/pdf/2407.08039
* Weston et al., "System 2 Attention(is something you might need too)", 20 Nov 2023, https://arxiv.org/pdf/2311.11829
* Yu et al., "Natural Language Reasoning, A Survey", 3 Oct 2024, https://dl.acm.org/doi/10.1145/3664194
* Dziri et al., " Faith and Fate: Limits of Transformers on Compositionality", 29 May 2023, https://arxiv.org/abs/2305.18654
* Cheng et al., "Inductive or Deductive? Rethinking the Fundamental Reasoning Abilities of LLMs", 7 Aug 2024, https://arxiv.org/pdf/2408.00114
* https://oreil.ly/llm-playbooks
* Kambhampati et al., "Position: LLMs Canâ€™t Plan, But Can Help Planning in LLM-Modulo Frameworks", 12 Jun 2024, https://arxiv.org/pdf/2402.01817
* Jin et al., "The Impact of Reasoning Step Length on Large Language Models", 22 Jun 2024, https://arxiv.org/pdf/2401.04925
* "huggingface SkunkworksAI/reasoning-0.01", https://oreil.ly/W1JRq
