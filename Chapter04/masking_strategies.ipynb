{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "22ItVJQY0sty"
      },
      "outputs": [],
      "source": [
        "! pip install transformers datasets sentence-transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate different masking rates"
      ],
      "metadata": {
        "id": "llUsjEtHg5ow"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JMiJO5RV8b84"
      },
      "outputs": [],
      "source": [
        "from transformers import Trainer, TrainingArguments, DataCollatorForLanguageModeling\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, AutoModelForMaskedLM, Trainer, TrainingArguments, DataCollatorForLanguageModeling\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "import math\n",
        "\n",
        "# Load Model & Tokenizer\n",
        "model_name = \"bert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForMaskedLM.from_pretrained(model_name)\n",
        "\n",
        "# Load Dataset\n",
        "dataset = load_dataset(\"wikitext\", \"wikitext-2-raw-v1\")\n",
        "\n",
        "# Tokenize Function\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(\n",
        "        examples['text'],\n",
        "        truncation=True,\n",
        "        padding='max_length',\n",
        "        max_length=128,\n",
        "        return_special_tokens_mask=True\n",
        "    )\n",
        "\n",
        "# Tokenize Dataset\n",
        "tokenized_datasets = dataset.map(\n",
        "    tokenize_function,\n",
        "    batched=True,\n",
        "    remove_columns=[\"text\"]\n",
        ")\n",
        "\n",
        "# Select 100 samples from train and validation\n",
        "train_subset = tokenized_datasets[\"train\"]\n",
        "eval_subset = tokenized_datasets[\"validation\"]\n",
        "\n",
        "# Training Arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./bert-mlm-custom-masking\",\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=10,\n",
        "    logging_steps=10,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=1,\n",
        "    save_steps=50,\n",
        "    save_total_limit=2\n",
        ")\n",
        "\n",
        "# Load Wikipedia-style question dataset (e.g., SQuAD or TriviaQA) for evaluation\n",
        "wiki_dataset = load_dataset(\"squad\", split=\"validation[:100]\")  # Sample 100 questions"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_perplexity(text):\n",
        "    \"\"\"\n",
        "    Calculates the perplexity of a given text using a pre-trained language model.\n",
        "\n",
        "    Perplexity is computed as the exponential of the loss from the model.\n",
        "    Lower perplexity indicates that the model is more confident in predicting the text.\n",
        "\n",
        "    Args:\n",
        "        text (str): The input text for which to compute perplexity.\n",
        "\n",
        "    Returns:\n",
        "        float: The perplexity score of the given text.\n",
        "    \"\"\"\n",
        "    # Tokenize the input text and convert it into tensors\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
        "    input_ids = inputs[\"input_ids\"]\n",
        "\n",
        "    # Perform inference without tracking gradients (to save memory and speed up computation)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, labels=input_ids)  # Compute the model loss\n",
        "        loss = outputs.loss.item()  # Extract the loss value\n",
        "\n",
        "    # Compute perplexity using the exponent of the loss\n",
        "    perplexity = math.exp(loss)\n",
        "    return perplexity\n",
        "\n",
        "\n",
        "def evaluate_masking_rates(model, training_args, train_subset, eval_subset, masking_rate=0.3, dataset=wiki_dataset):\n",
        "    \"\"\"\n",
        "    Evaluates the effect of different masking rates on model performance.\n",
        "\n",
        "    This function:\n",
        "    - Configures a data collator for masked language modeling.\n",
        "    - Trains the model on a given train subset.\n",
        "    - Evaluates the model on an evaluation subset.\n",
        "    - Computes and prints the loss on a single batch.\n",
        "    - Computes perplexity for Wikipedia-style questions.\n",
        "\n",
        "    Args:\n",
        "        model (transformers.PreTrainedModel): The pre-trained language model to be trained and evaluated.\n",
        "        training_args (transformers.TrainingArguments): Training configuration parameters.\n",
        "        train_subset (datasets.Dataset): The subset of the training dataset.\n",
        "        eval_subset (datasets.Dataset): The subset of the evaluation dataset.\n",
        "        masking_rate (float, optional): Probability of masking tokens during training. Defaults to 0.3.\n",
        "        dataset (datasets.Dataset, optional): Dataset containing Wikipedia questions for perplexity evaluation.\n",
        "\n",
        "    Returns:\n",
        "        None: Prints evaluation results including loss and perplexity scores.\n",
        "    \"\"\"\n",
        "\n",
        "    # Initialize the data collator for masked language modeling with the specified masking rate\n",
        "    data_collator = DataCollatorForLanguageModeling(\n",
        "        tokenizer=tokenizer,\n",
        "        mlm=True,\n",
        "        mlm_probability=masking_rate\n",
        "    )\n",
        "\n",
        "    # Set up the Trainer for training the model\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        data_collator=data_collator,\n",
        "        train_dataset=train_subset,\n",
        "        eval_dataset=eval_subset\n",
        "    )\n",
        "\n",
        "    # Train the model using the provided training data\n",
        "    trainer.train()\n",
        "\n",
        "    # Create a DataLoader to handle masked input processing\n",
        "    eval_dataloader = DataLoader(\n",
        "        eval_subset,\n",
        "        batch_size=8,  # Process data in mini-batches\n",
        "        collate_fn=data_collator  # Use the collator to apply masking\n",
        "    )\n",
        "\n",
        "    # Fetch one batch of evaluation data\n",
        "    batch = next(iter(eval_dataloader))\n",
        "\n",
        "    # Move the batch data to the model's device (e.g., GPU if available)\n",
        "    batch = {k: v.to(model.device) for k, v in batch.items()}\n",
        "\n",
        "    # Set the model to evaluation mode\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        # Compute the loss on the evaluation batch\n",
        "        outputs = model(**batch)\n",
        "        loss = outputs.loss\n",
        "\n",
        "    # Compute perplexity for Wikipedia-style questions from the dataset\n",
        "    perplexities = [calculate_perplexity(q) for q in dataset[\"question\"]]\n",
        "\n",
        "    # Print the masking rate and the loss value\n",
        "    print(f\"Evaluating masking rate of: {masking_rate:.2%} \\n\")\n",
        "    print(f\"Loss on a single batch: {loss.item()}\")\n",
        "    print(\"Average Perplexity:\", sum(perplexities) / len(perplexities))\n"
      ],
      "metadata": {
        "id": "Qg_LAELTiJAU"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_perplexity(text):\n",
        "    \"\"\"\n",
        "    Calculates the perplexity of a given text using a pre-trained language model.\n",
        "\n",
        "    Perplexity is computed as the exponential of the loss from the model.\n",
        "    Lower perplexity indicates that the model is more confident in predicting the text.\n",
        "\n",
        "    Args:\n",
        "        text (str): The input text for which to compute perplexity.\n",
        "\n",
        "    Returns:\n",
        "        float: The perplexity score of the given text.\n",
        "    \"\"\"\n",
        "    # Tokenize the input text and convert it into tensors\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
        "    input_ids = inputs[\"input_ids\"]\n",
        "\n",
        "    # Perform inference without tracking gradients (to save memory and speed up computation)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, labels=input_ids)  # Compute the model loss\n",
        "        loss = outputs.loss.item()  # Extract the loss value\n",
        "\n",
        "    # Compute perplexity using the exponent of the loss\n",
        "    perplexity = math.exp(loss)\n",
        "    return perplexity\n",
        "\n",
        "\n",
        "def evaluate_masking_rates(model, training_args, train_subset, eval_subset, masking_rate=0.3, dataset=wiki_dataset):\n",
        "    \"\"\"\n",
        "    Evaluates the effect of different masking rates on model performance.\n",
        "\n",
        "    This function:\n",
        "    - Configures a data collator for masked language modeling.\n",
        "    - Trains the model on a given train subset.\n",
        "    - Evaluates the model on an evaluation subset.\n",
        "    - Computes and prints the loss on a single batch.\n",
        "    - Computes perplexity for Wikipedia-style questions.\n",
        "\n",
        "    Args:\n",
        "        model (transformers.PreTrainedModel): The pre-trained language model to be trained and evaluated.\n",
        "        training_args (transformers.TrainingArguments): Training configuration parameters.\n",
        "        train_subset (datasets.Dataset): The subset of the training dataset.\n",
        "        eval_subset (datasets.Dataset): The subset of the evaluation dataset.\n",
        "        masking_rate (float, optional): Probability of masking tokens during training. Defaults to 0.3.\n",
        "        dataset (datasets.Dataset, optional): Dataset containing Wikipedia questions for perplexity evaluation.\n",
        "\n",
        "    Returns:\n",
        "        None: Prints evaluation results including loss and perplexity scores.\n",
        "    \"\"\"\n",
        "\n",
        "    # Initialize the data collator for masked language modeling with the specified masking rate\n",
        "    data_collator = DataCollatorForLanguageModeling(\n",
        "        tokenizer=tokenizer,\n",
        "        mlm=True,\n",
        "        mlm_probability=masking_rate\n",
        "    )\n",
        "\n",
        "    # Set up the Trainer for training the model\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        data_collator=data_collator,\n",
        "        train_dataset=train_subset,\n",
        "        eval_dataset=eval_subset\n",
        "    )\n",
        "\n",
        "    # Train the model using the provided training data\n",
        "    trainer.train()\n",
        "\n",
        "    # Create a DataLoader to handle masked input processing\n",
        "    eval_dataloader = DataLoader(\n",
        "        eval_subset,\n",
        "        batch_size=8,  # Process data in mini-batches\n",
        "        collate_fn=data_collator  # Use the collator to apply masking\n",
        "    )\n",
        "\n",
        "    # Move model to evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    total_loss = 0.0\n",
        "    num_batches = 0\n",
        "\n",
        "    # Iterate through the full evaluation dataset\n",
        "    with torch.no_grad():\n",
        "        for batch in eval_dataloader:\n",
        "            batch = {k: v.to(model.device) for k, v in batch.items()}\n",
        "            outputs = model(**batch)\n",
        "            total_loss += outputs.loss.item()\n",
        "            num_batches += 1\n",
        "\n",
        "    # Compute the average loss across all batches\n",
        "    avg_loss = total_loss / num_batches\n",
        "    perplexity = math.exp(avg_loss)\n",
        "\n",
        "    # Print loss\n",
        "    print(f\"Evaluating masking rate of: {masking_rate:.2%} \\n\")\n",
        "    print(f\"Average Loss across Eval Set: {avg_loss:.4f}\")\n",
        "    print(f\"Perplexity across Eval Set: {perplexity:.4f}\")\n",
        "\n",
        "    # Compute perplexity for Wikipedia-style questions from the dataset\n",
        "    perplexities = [calculate_perplexity(q) for q in dataset[\"question\"]]\n",
        "\n",
        "    # Print the perplexity\n",
        "    print(\"Average Perplexity:\", sum(perplexities) / len(perplexities))"
      ],
      "metadata": {
        "id": "mlnbA134ZgTR"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note to reader: this is where you can try different masking rates and evaluate based on loss and perplexity yourself."
      ],
      "metadata": {
        "id": "SA0kTPOXmEf3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_masking_rates(model, training_args, train_subset, eval_subset, 0.3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "id": "OE4TqKRzjxZ6",
        "outputId": "64b868e6-4580-40b8-f17b-2ecff1948e4d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [13/13 04:25, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.374200</td>\n",
              "      <td>2.980839</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating masking rate of: 30.00%\n",
            "Average Loss across Eval Set: 3.0823\n",
            "Perplexity across Eval Set: 21.8085\n",
            "Evaluating masking rate of: 30.00% \n",
            "\n",
            "Average Perplexity: 43.06413626229333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_masking_rates(model, training_args, train_subset, eval_subset, 0.5)"
      ],
      "metadata": {
        "id": "APxLvDR8lZGT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pP2lhkSQo-8Y"
      },
      "source": [
        "# Masking based on heuristics:\n",
        "\n",
        "In this example, we will mask based on frequency of a word's occurence within the corpus. If its frequency is below a certain threshold, it will be more likely to be masked."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 440
        },
        "id": "dnaXrHRo3jQZ",
        "outputId": "52089cad-9fe9-49bd-fcd1-16b890ecf477"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='22' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [22/25 05:47 < 00:52, 0.06 it/s, Epoch 0.84/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>8.069200</td>\n",
              "      <td>5.784812</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>5.074100</td>\n",
              "      <td>4.497670</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [25/25 07:14, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>8.069200</td>\n",
              "      <td>5.784812</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>5.074100</td>\n",
              "      <td>4.497670</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=25, training_loss=6.260419082641602, metrics={'train_runtime': 452.5074, 'train_samples_per_second': 0.221, 'train_steps_per_second': 0.055, 'total_flos': 9080566041600.0, 'train_loss': 6.260419082641602, 'epoch': 1.0})"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
        "from datasets import load_dataset\n",
        "import torch\n",
        "\n",
        "\n",
        "# Load model & tokenizer\n",
        "model_name = \"bert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForMaskedLM.from_pretrained(model_name)\n",
        "\n",
        "# Load dataset\n",
        "dataset = load_dataset(\"wikitext\", \"wikitext-2-raw-v1\")\n",
        "train_dataset = dataset['train']\n",
        "eval_dataset = dataset['validation']\n",
        "\n",
        "# Build Frequency Dictionary\n",
        "all_tokens = [word for sentence in train_dataset['text'] for word in sentence.split(' ')]\n",
        "token_ids = tokenizer(all_tokens, add_special_tokens=False)['input_ids']\n",
        "flat_token_ids = [token_id for sublist in token_ids for token_id in sublist]\n",
        "freq_dict = {token_id: flat_token_ids.count(token_id) for token_id in set(flat_token_ids)}\n",
        "\n",
        "\n",
        "# Custom Collator For Frequency Based Masking\n",
        "class LowFrequencyMaskingCollator:\n",
        "    def __init__(self, tokenizer, freq_dict, mask_prob=0.3, rare_threshold=5):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.freq_dict = freq_dict\n",
        "        self.mask_prob = mask_prob\n",
        "        self.rare_threshold = rare_threshold\n",
        "\n",
        "    def __call__(self, examples):\n",
        "        # Extract the text column\n",
        "        texts = [example['text'] for example in examples]\n",
        "\n",
        "        # Tokenize\n",
        "        batch = self.tokenizer(texts, padding=True, truncation=True, return_tensors='pt')\n",
        "\n",
        "        input_ids = batch['input_ids']\n",
        "        labels = input_ids.clone()\n",
        "\n",
        "        for i in range(input_ids.shape[0]):\n",
        "            for j in range(input_ids.shape[1]):\n",
        "                token_id = input_ids[i, j].item()\n",
        "                freq = self.freq_dict.get(token_id, 0)\n",
        "\n",
        "                if freq < self.rare_threshold:\n",
        "                    mask_prob = self.mask_prob * 2\n",
        "                else:\n",
        "                    mask_prob = self.mask_prob\n",
        "\n",
        "                if torch.rand(1).item() < mask_prob:\n",
        "                    input_ids[i, j] = self.tokenizer.mask_token_id\n",
        "\n",
        "        batch['input_ids'] = input_ids\n",
        "        batch['labels'] = labels\n",
        "\n",
        "        return batch\n",
        "\n",
        "\n",
        "collator = LowFrequencyMaskingCollator(tokenizer, freq_dict)\n",
        "\n",
        "\n",
        "# Training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./bert-mlm-custom-masking\",\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=10,\n",
        "    logging_steps=10,\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    num_train_epochs=1,\n",
        "    save_steps=50,\n",
        "    save_total_limit=1,\n",
        "    remove_unused_columns=False\n",
        ")\n",
        "\n",
        "# Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=collator,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        ")\n",
        "\n",
        "# Train\n",
        "trainer.train()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note to reader: experiment with different masking and frequency threshold rates by inputting different values into the data collator in the cell above. How does it affect loss and perplexity below?"
      ],
      "metadata": {
        "id": "p22mGrGuotGt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_frequency_based_masking( model, data_collator,eval_subset=eval_dataset, dataset=wiki_dataset):\n",
        "    \"\"\"\n",
        "    Evaluates the effect of different masking rates on model performance.\n",
        "\n",
        "    This function:\n",
        "    - Evaluates the model on an evaluation subset.\n",
        "    - Computes and prints the loss on a single batch.\n",
        "    - Computes perplexity for Wikipedia-style questions.\n",
        "\n",
        "    Args:\n",
        "        model (transformers.PreTrainedModel): The pre-trained language model to be trained and evaluated.\n",
        "        eval_subset (datasets.Dataset, optional): The subset of the evaluation dataset. Defaults to eval subset from previous cell.\n",
        "        dataset (datasets.Dataset, optional): Dataset containing Wikipedia questions for perplexity evaluation.\n",
        "\n",
        "    Returns:\n",
        "        None: Prints evaluation results including loss and perplexity scores.\n",
        "    \"\"\"\n",
        "    # Create a DataLoader to handle masked input processing\n",
        "    eval_dataloader = DataLoader(\n",
        "        eval_subset,\n",
        "        batch_size=8,  # Process data in mini-batches\n",
        "        collate_fn=data_collator  # Use the collator to apply masking\n",
        "    )\n",
        "\n",
        "    # Move model to evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    total_loss = 0.0\n",
        "    num_batches = 0\n",
        "\n",
        "    # Iterate through the full evaluation dataset\n",
        "    with torch.no_grad():\n",
        "        for batch in eval_dataloader:\n",
        "            batch = {k: v.to(model.device) for k, v in batch.items()}\n",
        "            outputs = model(**batch)\n",
        "            total_loss += outputs.loss.item()\n",
        "            num_batches += 1\n",
        "\n",
        "    # Compute the average loss across all batches\n",
        "    avg_loss = total_loss / num_batches\n",
        "    perplexity = math.exp(avg_loss)\n",
        "\n",
        "    # Print loss\n",
        "    print(f\"Average Loss across Eval Set: {avg_loss:.4f}\")\n",
        "    print(f\"Perplexity across Eval Set: {perplexity:.4f}\")\n",
        "\n",
        "    # Compute perplexity for Wikipedia-style questions from the dataset\n",
        "    perplexities = [calculate_perplexity(q) for q in dataset[\"question\"]]\n",
        "\n",
        "    # Print the loss and average perplexity\n",
        "    print(\"Average Perplexity:\", sum(perplexities) / len(perplexities))\n"
      ],
      "metadata": {
        "id": "7VbBRia_n6q-"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_frequency_based_masking(model, collator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D0tQf74dqJx0",
        "outputId": "062d794a-acf0-4eba-fb65-e0b61e82195a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Loss across Eval Set: 4.1630\n",
            "Perplexity across Eval Set: 64.2658\n",
            "Average Perplexity: 12.48361186605892\n",
            "Average Perplexity: 12.48361186605892\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Note to reader: can we also mask based on part of speech tags?"
      ],
      "metadata": {
        "id": "-R8k88xYqWpe"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}