# Chapter 11

## Notebooks

* [negation_aware.ipynb](https://colab.research.google.com/github/your-username/designing-llm-apps/blob/main/Chapter11/negation_aware.ipynb)

## References 
* "Vector Similarity Explained: Understanding Distance Metrics for Search and ML", https://www.pinecone.io/learn/vector-similarity/
* "Sentence Transformers Documentation", https://oreil.ly/8QpBj
* "SentenceTransformerTrainer", https://oreil.ly/Jahep
* "BAAI/bge-m3: Multilingual Embedding Model", https://huggingface.co/BAAI/bge-m3
* "Jina AI Embeddings v3: Advanced Text Embedding Model", https://huggingface.co/jinaai/jina-embeddings-v3
* "Sentence Transformers Training Examples", https://oreil.ly/Onyuv
* Moreira et al., "NV-Retriever: Improving text embedding models with effective hard-negative mining", 7 Feb 2025, https://arxiv.org/pdf/2407.15831
* "Sentence Transformers Dataset Overview: Summary of Available Datasets and Their Characteristics", https://oreil.ly/geI1M
* "MultipleNegativesRankingLoss", https://oreil.ly/oNcsQ
* "CachedMultipleNegativesRankingLoss", https://oreil.ly/QwBlI
* "Designing Large Language Model Applications", https://oreil.ly/llm-playbooks
* Zhou et al., "Problems with Cosine as a Measure of Embedding Similarity for High Frequency Words", 10 May 2022, https://oreil.ly/BPdRD
* Ravfogel et al., "Description-Based Text Similarity", 24 Jul 2024, https://arxiv.org/pdf/2305.12517
* https://github.com/UKPLab/sentence-transformers/tree/master/examples/sentence_transformer/training/matryoshka
* Li et al., "2D Matryoshka Sentence Embeddings", 30 Nov 2024, https://arxiv.org/abs/2402.14776
* "Adaptive Layers", https://oreil.ly/DIoTe
* "Matryoshka2dLoss", https://oreil.ly/xzG-a
* "News Category Dataset - kaggle", https://oreil.ly/Tu4XA
* "nomic-ai/nomic-embed-text-v1.5", https://oreil.ly/jALJE
* "Binary and Scalar Embedding Quantization for Significantly Faster & Cheaper Retrieval", https://oreil.ly/Mp3pu
* "Product Quantization for Model Compression, https://oreil.ly/aJq2C
* "Cohere/wikipedia-22-12-simple-embeddings", https://oreil.ly/OUq5M
* "NLTK의 Punkt 문장 토크나이저 모듈 공식 문서", https://oreil.ly/bgxrp
* "spaCy 라이브러리 공식 사용법 가이드", https://spacy.io/usage
* "Tokenization & Sentence Segmentation", https://oreil.ly/xKo43
* "Sentence Tokenization", https://oreil.ly/fxvBi
* "Designing Large Language Model Applications - GitHub 저장소", https://oreil.ly/llm-playbooks
* "Unstructured.io - 문서 처리 및 데이터 추출 플랫폼", https://unstructured.io/
* "Understanding Bollinger Bands: A Key Technical Analysis Tool for Investors", https://oreil.ly/1MwK1
* "jina_text_segmenter.py", https://oreil.ly/x5UO8
* Adam Karvonen, "An Intuitive Explanation of Sparse Autoencoders for LLM Interpretability", 11 Jun 2024, https://oreil.ly/oiXb7
* Linus Lee, "Prism: mapping interpretable concepts and features in a latent space of language", 22 June, 2024, https://oreil.ly/efzz1
